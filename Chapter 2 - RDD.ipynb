{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2 RDD(Resilient Distributed Datasets)\n",
    "### 내부작동원리\n",
    "----------------\n",
    "스파크의 가장 큰 장점 - 병렬로 동작하는 RDD / \n",
    "각 트랜스포메이션은 속도를 비약적으로 향상시키기 위해 실행 / \n",
    "모든 트랜스포메이션은 데이터셋에 대한 액션이 호출됐을 때 실행 \n",
    "\n",
    "### RDD 생성하기\n",
    "-------------------\n",
    "RDD를 생성하는 방법은 두가지이다.\n",
    "1. 컬렉션에 대해 parallelize()함수를 수행\n",
    "\n",
    "2. 파일 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sc.parallelize(\n",
    "    [('Amber', 22), ('Alfred', 23), ('Skye',4), ('Albert', 12), \n",
    "     ('Amber', 9)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "보통 한 클러스터에서 2~4개 정도의 파티션으로 데이터 셋을 나누는 것이 좋다.\n",
    "sc.textFile(A, n)에서 n은 데이터셋이 나눠진 파티션 개수를 의미"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_from_file = sc.textFile('./data/VS14MORT.txt.gz',4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Schema**\n",
    "\n",
    "RDD는 데이터프레임과 달리 스키마리스 구조. 데이터셋에 대해 .collect() 함수를 수행하면 파이썬에서도 객체 내의 데이터에 접근할 수 있다\n",
    "\n",
    ".collect() 함수는 RDD의 모든 엘리먼트를 드라이버에 리턴, 드라이버에서 엘리먼트들은 리스트로 나열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Ferrari', 'fast'), {'Porsche': 100000}, ['Spain', 'visited', 4504]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_heterogenous = sc.parallelize([('Ferrari', 'fast'), {'Porsche': 100000}, ['Spain','visited', 4504]]).collect()\n",
    "data_heterogenous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_heterogenous[1]['Porsche']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**파일로부터 데이터 읽기**\n",
    "\n",
    "\n",
    "\n",
    "텍스트 파일을 읽을때 파일의 각 행이 RDD의 한 엘리먼트를 이룬다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['                   1                                          2101  M1087 432311  4M4                2014U7CN                                    I64 238 070   24 0111I64                                                                                                                                                                           01 I64                                                                                                  01  11                                 100 601']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_from_file.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lambda**\n",
    "\n",
    "\n",
    "주의: 일반적인 파이썬 함수 선언시 스파크가 파이썬 인터프리터와 JVM을 지속적으로 스위치 하기에 느려질 수 있다. 가능하면 반드시 스파크 내장 함수를 사용하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractInformation(row):\n",
    "    import re\n",
    "    import numpy as np\n",
    "\n",
    "    selected_indices = [\n",
    "         2,4,5,6,7,9,10,11,12,13,14,15,16,17,18,\n",
    "         19,21,22,23,24,25,27,28,29,30,32,33,34,\n",
    "         36,37,38,39,40,41,42,43,44,45,46,47,48,\n",
    "         49,50,51,52,53,54,55,56,58,60,61,62,63,\n",
    "         64,65,66,67,68,69,70,71,72,73,74,75,76,\n",
    "         77,78,79,81,82,83,84,85,87,89\n",
    "    ]\n",
    "\n",
    "    '''\n",
    "        Input record schema\n",
    "        schema: n-m (o) -- xxx\n",
    "            n - position from\n",
    "            m - position to\n",
    "            o - number of characters\n",
    "            xxx - description\n",
    "        1. 1-19 (19) -- reserved positions\n",
    "        2. 20 (1) -- resident status\n",
    "        3. 21-60 (40) -- reserved positions\n",
    "        4. 61-62 (2) -- education code (1989 revision)\n",
    "        5. 63 (1) -- education code (2003 revision)\n",
    "        6. 64 (1) -- education reporting flag\n",
    "        7. 65-66 (2) -- month of death\n",
    "        8. 67-68 (2) -- reserved positions\n",
    "        9. 69 (1) -- sex\n",
    "        10. 70 (1) -- age: 1-years, 2-months, 4-days, 5-hours, 6-minutes, 9-not stated\n",
    "        11. 71-73 (3) -- number of units (years, months etc)\n",
    "        12. 74 (1) -- age substitution flag (if the age reported in positions 70-74 is calculated using dates of birth and death)\n",
    "        13. 75-76 (2) -- age recoded into 52 categories\n",
    "        14. 77-78 (2) -- age recoded into 27 categories\n",
    "        15. 79-80 (2) -- age recoded into 12 categories\n",
    "        16. 81-82 (2) -- infant age recoded into 22 categories\n",
    "        17. 83 (1) -- place of death\n",
    "        18. 84 (1) -- marital status\n",
    "        19. 85 (1) -- day of the week of death\n",
    "        20. 86-101 (16) -- reserved positions\n",
    "        21. 102-105 (4) -- current year\n",
    "        22. 106 (1) -- injury at work\n",
    "        23. 107 (1) -- manner of death\n",
    "        24. 108 (1) -- manner of disposition\n",
    "        25. 109 (1) -- autopsy\n",
    "        26. 110-143 (34) -- reserved positions\n",
    "        27. 144 (1) -- activity code\n",
    "        28. 145 (1) -- place of injury\n",
    "        29. 146-149 (4) -- ICD code\n",
    "        30. 150-152 (3) -- 358 cause recode\n",
    "        31. 153 (1) -- reserved position\n",
    "        32. 154-156 (3) -- 113 cause recode\n",
    "        33. 157-159 (3) -- 130 infant cause recode\n",
    "        34. 160-161 (2) -- 39 cause recode\n",
    "        35. 162 (1) -- reserved position\n",
    "        36. 163-164 (2) -- number of entity-axis conditions\n",
    "        37-56. 165-304 (140) -- list of up to 20 conditions\n",
    "        57. 305-340 (36) -- reserved positions\n",
    "        58. 341-342 (2) -- number of record axis conditions\n",
    "        59. 343 (1) -- reserved position\n",
    "        60-79. 344-443 (100) -- record axis conditions\n",
    "        80. 444 (1) -- reserve position\n",
    "        81. 445-446 (2) -- race\n",
    "        82. 447 (1) -- bridged race flag\n",
    "        83. 448 (1) -- race imputation flag\n",
    "        84. 449 (1) -- race recode (3 categories)\n",
    "        85. 450 (1) -- race recode (5 categories)\n",
    "        86. 461-483 (33) -- reserved positions\n",
    "        87. 484-486 (3) -- Hispanic origin\n",
    "        88. 487 (1) -- reserved\n",
    "        89. 488 (1) -- Hispanic origin/race recode\n",
    "     '''\n",
    "\n",
    "    record_split = re\\\n",
    "        .compile(\n",
    "            r'([\\s]{19})([0-9]{1})([\\s]{40})([0-9\\s]{2})([0-9\\s]{1})([0-9]{1})([0-9]{2})' + \n",
    "            r'([\\s]{2})([FM]{1})([0-9]{1})([0-9]{3})([0-9\\s]{1})([0-9]{2})([0-9]{2})' + \n",
    "            r'([0-9]{2})([0-9\\s]{2})([0-9]{1})([SMWDU]{1})([0-9]{1})([\\s]{16})([0-9]{4})' +\n",
    "            r'([YNU]{1})([0-9\\s]{1})([BCOU]{1})([YNU]{1})([\\s]{34})([0-9\\s]{1})([0-9\\s]{1})' +\n",
    "            r'([A-Z0-9\\s]{4})([0-9]{3})([\\s]{1})([0-9\\s]{3})([0-9\\s]{3})([0-9\\s]{2})([\\s]{1})' + \n",
    "            r'([0-9\\s]{2})([A-Z0-9\\s]{7})([A-Z0-9\\s]{7})([A-Z0-9\\s]{7})([A-Z0-9\\s]{7})' + \n",
    "            r'([A-Z0-9\\s]{7})([A-Z0-9\\s]{7})([A-Z0-9\\s]{7})([A-Z0-9\\s]{7})([A-Z0-9\\s]{7})' + \n",
    "            r'([A-Z0-9\\s]{7})([A-Z0-9\\s]{7})([A-Z0-9\\s]{7})([A-Z0-9\\s]{7})([A-Z0-9\\s]{7})' + \n",
    "            r'([A-Z0-9\\s]{7})([A-Z0-9\\s]{7})([A-Z0-9\\s]{7})([A-Z0-9\\s]{7})([A-Z0-9\\s]{7})' + \n",
    "            r'([A-Z0-9\\s]{7})([\\s]{36})([A-Z0-9\\s]{2})([\\s]{1})([A-Z0-9\\s]{5})([A-Z0-9\\s]{5})' + \n",
    "            r'([A-Z0-9\\s]{5})([A-Z0-9\\s]{5})([A-Z0-9\\s]{5})([A-Z0-9\\s]{5})([A-Z0-9\\s]{5})' + \n",
    "            r'([A-Z0-9\\s]{5})([A-Z0-9\\s]{5})([A-Z0-9\\s]{5})([A-Z0-9\\s]{5})([A-Z0-9\\s]{5})' + \n",
    "            r'([A-Z0-9\\s]{5})([A-Z0-9\\s]{5})([A-Z0-9\\s]{5})([A-Z0-9\\s]{5})([A-Z0-9\\s]{5})' + \n",
    "            r'([A-Z0-9\\s]{5})([A-Z0-9\\s]{5})([A-Z0-9\\s]{5})([\\s]{1})([0-9\\s]{2})([0-9\\s]{1})' + \n",
    "            r'([0-9\\s]{1})([0-9\\s]{1})([0-9\\s]{1})([\\s]{33})([0-9\\s]{3})([0-9\\s]{1})([0-9\\s]{1})')\n",
    "    try:\n",
    "        rs = np.array(record_split.split(row))[selected_indices]\n",
    "    except:\n",
    "        rs = np.array(['-99'] * len(selected_indices))\n",
    "    return rs\n",
    "#     return record_split.split(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터셋을 쪼개고 변형하기 위해 extractinformation() 사용. map() 함수에 오로지 함수 시그니처만 전달(이 함수는 각 파티션에서 RDD 내의 한 데이터만 extractinformation() 함수에 전달)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['1', '  ', '2', '1', '01', 'M', '1', '087', ' ', '43', '23', '11',\n",
       "        '  ', '4', 'M', '4', '2014', 'U', '7', 'C', 'N', ' ', ' ', 'I64 ',\n",
       "        '238', '070', '   ', '24', '01', '11I64  ', '       ', '       ',\n",
       "        '       ', '       ', '       ', '       ', '       ', '       ',\n",
       "        '       ', '       ', '       ', '       ', '       ', '       ',\n",
       "        '       ', '       ', '       ', '       ', '       ', '01',\n",
       "        'I64  ', '     ', '     ', '     ', '     ', '     ', '     ',\n",
       "        '     ', '     ', '     ', '     ', '     ', '     ', '     ',\n",
       "        '     ', '     ', '     ', '     ', '     ', '     ', '01', ' ',\n",
       "        ' ', '1', '1', '100', '6'], dtype='<U40')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_from_file_conv = data_from_file.map(extractInformation)\n",
    "data_from_file_conv.map(lambda row: row).take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전역 범위 vs 지역 범위\n",
    "----------------\n",
    "\n",
    "스파크는 로컬 모드, 클러스터 모드로 동작한다. 스파크가 로컬모드로 동작할 때는 파이썬을 실행시키는 것과 다르지 않을 수도 있다.\n",
    "참고: https://spark.apache.org/docs/latest/rdd-programming-guide.html#local-vs-cluster-modes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformations\n",
    "------------------\n",
    "필터링, 조인, 데이터셋 내의 값들에 대한 트랜스코딩등을 포함한 데이터셋의 형태를 만드는 것.\n",
    "\n",
    "**.map()**\n",
    "\n",
    "가장 많이 쓰이는 함수. 이 함수는 RDD의 각 엘리먼트에 적용된다. data_from_file_conv 데이터셋에서 이 함수를 각각의 행에 대한 트렌스포메이션으로 볼 수 있다. 리스트 형태로 리턴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_2014.take(10)\n",
      " [2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, -99]\n",
      "\n",
      "data_2014_2.take(10)\n",
      " [('2014', 'M'), ('2014', 'M'), ('2014', 'F'), ('2014', 'M'), ('2014', 'M'), ('2014', 'F'), ('2014', 'M'), ('2014', 'M'), ('2014', 'F'), ('-99', '-99')]\n"
     ]
    }
   ],
   "source": [
    "data_2014 = data_from_file_conv.map(lambda row: int(row[16])) #사망날짜를 숫자값으로 변형\n",
    "data_2014_2 = data_from_file_conv.map(lambda row: (row[16], row[5])) #사망날짜와 성별\n",
    "print(\"data_2014.take(10)\\n\",data_2014.take(10))\n",
    "print(\"\\ndata_2014_2.take(10)\\n\",data_2014_2.take(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**.flatMap()**\n",
    "\n",
    ".map() 함수와 비슷하게 동작. 그러나 평면화된 결과를 리턴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2014, 'M', 2014, 'M', 2014, 'F', 2014, 'M', 2014, 'M']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2014_flat = data_from_file_conv.flatMap(lambda row: (int(row[16]), row[5]))\n",
    "data_2014_flat.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**.filter()**\n",
    "\n",
    "특정 조건에 맞는 엘리먼트 선택 가능. 2014년에 사고사 인원을 카운트 해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_filtered = data_from_file_conv.filter(\n",
    "    lambda row: row[16]=='2014' and row[21] =='0')\n",
    "data_filtered.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**.distinct()**\n",
    "\n",
    "특정 칼럼에서의 중복된 값을 제거하여 고유값을 리스트로 리턴\n",
    "\n",
    "성별을 나타내는 row[5]에 또 다른 값이 있는지 확인. \n",
    "\n",
    ".collect()함수는 많은 자원을 사용하고 데이터를 섞는 연산을 포함하기에 필요할때만 쓰자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-99', 'M', 'F']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct_gender = data_from_file_conv.map(lambda row: row[5]).distinct().collect()\n",
    "distinct_gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**.sample()**\n",
    "\n",
    "데이터셋에서 임의로 추출된 샘플을 리턴\n",
    "\n",
    ".sample(중복여부,리턴할데이터셋과 전체 데이터셋 간의 크기 비율, 랜덤시드)\n",
    "원본데이터와 샘플데이터의 count를 확인해보니 10%에 해당하는 임의의 샘플을 얻었다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(['1', '  ', '5', '1', '01', 'F', '1', '082', ' ', '42', '22', '10',\n",
      "       '  ', '4', 'W', '5', '2014', 'U', '7', 'C', 'N', ' ', ' ', 'I251',\n",
      "       '215', '063', '   ', '21', '02', '11I350 ', '21I251 ', '       ',\n",
      "       '       ', '       ', '       ', '       ', '       ', '       ',\n",
      "       '       ', '       ', '       ', '       ', '       ', '       ',\n",
      "       '       ', '       ', '       ', '       ', '       ', '02',\n",
      "       'I251 ', 'I350 ', '     ', '     ', '     ', '     ', '     ',\n",
      "       '     ', '     ', '     ', '     ', '     ', '     ', '     ',\n",
      "       '     ', '     ', '     ', '     ', '     ', '     ', '28', ' ',\n",
      "       ' ', '2', '4', '100', '8'], dtype='<U40')]\n",
      "Original dataset: 2631171, sample: 263247\n"
     ]
    }
   ],
   "source": [
    "fraction = 0.1\n",
    "data_sample = data_from_file_conv.sample(False, fraction, 666)\n",
    "\n",
    "print(data_sample.take(1))\n",
    "print('Original dataset: {0}, sample: {1}'.format(data_from_file_conv.count(), data_sample.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**.leftOuterJoin()**\n",
    "\n",
    "왼쪽 RDD에 오른쪽 RDD가 추가된 결과가 리턴\n",
    "데이터를 섞는 과정을 포함하므로 성능저하가 올 수 있다. 필요할때만 쓰자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('c', (10, None)), ('b', (4, '6')), ('a', (1, 4)), ('a', (1, 1))]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1 = sc.parallelize([('a', 1), ('b', 4), ('c',10)])\n",
    "rdd2 = sc.parallelize([('a', 4), ('a', 1), ('b', '6'), ('d', 15)])\n",
    "rdd3 = rdd1.leftOuterJoin(rdd2)\n",
    "rdd3.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**.join()**\n",
    "\n",
    "두 RDD에서 'a'와 'b'가 겹치므로 두 값만 가짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('b', (4, '6')), ('a', (1, 4)), ('a', (1, 1))]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd4 = rdd1.join(rdd2)\n",
    "rdd4.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**.intersection()**\n",
    "\n",
    "두 RDD의 교집합 엘리먼트를 리턴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 1)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd5 = rdd1.intersection(rdd2)\n",
    "rdd5.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**.repartition()**\n",
    "\n",
    "데이터셋을 재파티션. 성능저하 올 수 있음. \n",
    "\n",
    ".glom()이 생성하는 리스트는 파티션 개수만큼의 엘리먼트를 가지고 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1 = rdd1.repartition(4)\n",
    "len(rdd1.glom().collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Action\n",
    "\n",
    "트랜스포메이션과는 다르게 Action은 데이터셋에서 스케줄된 태스크를 실행\n",
    "\n",
    "트랜스포메이션 경우, 데이터 트랜스포메이션이 끝난 후 트랜스포메이션 실행 가능\n",
    "\n",
    "액션은 어떠한 트랜스포메이션도 포함하지 않거나(예로, .take(n)은 어떠한 트랜스포메이션이 수행되지 않아도 RDD에서 n개의 데이터 리턴) 어떠한 트랜스포메이션도 될 수 있다.\n",
    "\n",
    "**.take()**\n",
    "\n",
    "가장 위에 있는 n행 리턴. RDD 전체를 리턴하는 .collect()보다 더 자주 쓰임."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['1', '  ', '2', '1', '01', 'M', '1', '087', ' ', '43', '23', '11',\n",
       "        '  ', '4', 'M', '4', '2014', 'U', '7', 'C', 'N', ' ', ' ', 'I64 ',\n",
       "        '238', '070', '   ', '24', '01', '11I64  ', '       ', '       ',\n",
       "        '       ', '       ', '       ', '       ', '       ', '       ',\n",
       "        '       ', '       ', '       ', '       ', '       ', '       ',\n",
       "        '       ', '       ', '       ', '       ', '       ', '01',\n",
       "        'I64  ', '     ', '     ', '     ', '     ', '     ', '     ',\n",
       "        '     ', '     ', '     ', '     ', '     ', '     ', '     ',\n",
       "        '     ', '     ', '     ', '     ', '     ', '     ', '01', ' ',\n",
       "        ' ', '1', '1', '100', '6'], dtype='<U40')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_first = data_from_file_conv.take(1)\n",
    "data_first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**.takeSample(a,b,c)**\n",
    "\n",
    "데이터로부터 임의의 샘플을 얻는다.\n",
    "\n",
    "a: 샘플링이 재선택되는 경우 허용 여부\n",
    "\n",
    "b: 리턴 데이터 개수\n",
    "\n",
    "c: 랜덤시드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['1', '  ', '3', '1', '09', 'F', '1', '086', ' ', '43', '23', '11',\n",
       "        '  ', '4', 'D', '2', '2014', 'U', '7', 'B', 'U', ' ', ' ', 'N185',\n",
       "        '327', '100', '   ', '31', '04', '11N185 ', '12I500 ', '61J189 ',\n",
       "        '62E46  ', '       ', '       ', '       ', '       ', '       ',\n",
       "        '       ', '       ', '       ', '       ', '       ', '       ',\n",
       "        '       ', '       ', '       ', '       ', '       ', '04',\n",
       "        'N185 ', 'E46  ', 'I500 ', 'J189 ', '     ', '     ', '     ',\n",
       "        '     ', '     ', '     ', '     ', '     ', '     ', '     ',\n",
       "        '     ', '     ', '     ', '     ', '     ', '     ', '01', ' ',\n",
       "        ' ', '1', '1', '100', '6'], dtype='<U40')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_take_sampled = data_from_file_conv.takeSample(False,1,911)\n",
    "data_take_sampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**.collect()**\n",
    "\n",
    "RDD의 모든 엘리먼트를 드라이버로 리턴한다. 데이터셋이 클수록 많은 연산이 요구되므로 성능저하의 주요 원인\n",
    "\n",
    "**.reduce()**\n",
    "\n",
    ".reduce() 함수는 특정 함수를 사용해 RDD의 개수를 줄인다. RDD의 총합을 구하기 위해 이 함수를 사용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "map result: PythonRDD[53] at RDD at PythonRDD.scala:52\n",
      "reduce result: 15\n"
     ]
    }
   ],
   "source": [
    "# map()을 이용해 RDD1의 값 리스트 생성\n",
    "temp_for_reduce = rdd1.map(lambda row: row[1])\n",
    "print(\"map result:\",temp_for_reduce)\n",
    "\n",
    "# 각 파티션에서 합계 함수를 수행(여기서 lambda로 표기)\n",
    "# 마지막 집계가 수행되는 드라이버 노드에 합계 리턴\n",
    "redu = temp_for_reduce.reduce(lambda x, y: x + y)\n",
    "print(\"reduce result:\",redu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "주의: 리듀서로 전달되는 함수는 결합법칙, 교환법칙이 성립해야한다. 즉, 엘리먼트 순서가 바뀌어도, 피연산자의 순서가 바뀌어도 결과는 같아야 한다.\n",
    "\n",
    "아래처럼 같은 데이터이나 파티션을 나눔에 따라 결과가 다르게 도출된다. 어떤 함수를 리듀서로 정할지 신중히 결정해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One partion, use reduce:\t 10.0\n",
      "Three partion, use reduce:\t 0.004\n"
     ]
    }
   ],
   "source": [
    "data_reduce = sc.parallelize([1,2,.5,.1,5,.2],1)\n",
    "print(\"One partion, use reduce:\\t\",data_reduce.reduce(lambda x, y: x / y))\n",
    "\n",
    "data_reduce = sc.parallelize([1,2,.5,.1,5,.2],3)\n",
    "print(\"Three partion, use reduce:\\t\",data_reduce.reduce(lambda x, y: x / y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**.reduceByKey()**\n",
    "\n",
    ".reduce() 함수와 비슷하게 동작하나 .reduceByKey()는 키 값을 기반으로 리듀스 하는 것이 차이점"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('b', 4), ('c', 2), ('a', 12), ('d', 5)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_key = sc.parallelize([('a', 4),('b', 3),('c', 2),('a', 8),('d', 2),('b', 1),('d', 3)],4)\n",
    "data_key.reduceByKey(lambda x, y: x + y).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**.count()**\n",
    "\n",
    "RDD 엘리먼트 개수를 리턴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_reduce.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**.countByKey()**\n",
    "\n",
    "데이터셋이 키-값 형태라면 고유 키의 수를 구할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('a', 2), ('b', 2), ('d', 2), ('c', 1)])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_key.countByKey().items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**.saveAsTextFile()**\n",
    "\n",
    "RDD를 텍스트파일로 저장한다. 모든 행은 스트링으로 표시된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_key.saveAsTextFile('./data/data_key.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('b', 1), ('d', 3), ('a', 8), ('d', 2), ('a', 4), ('b', 3), ('c', 2)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parseInput(row):\n",
    "    import re\n",
    "    \n",
    "    pattern = re.compile(r'\\(\\'([a-z])\\', ([0-9])\\)')\n",
    "    row_split = pattern.split(row)\n",
    "    \n",
    "    return (row_split[1], int(row_split[2]))\n",
    "    \n",
    "data_key_reread = sc.textFile('./data/data_key.txt').map(parseInput)\n",
    "data_key_reread.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**.foreach()**\n",
    "\n",
    "같은 함수를 RDD의 각 엘리먼트에 반복적으로 적용하는 함수. map()과 달리 정의된 함수를 하나하나 각각의 데이터에 적용.PySpark에서 지원하지 않는 DB에 데이터를 저장하고 싶을 때 유용하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x): \n",
    "    print(x)\n",
    "\n",
    "data_reduce.foreach(f) #data_key RDD에 저장된 모든 데이터를 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
